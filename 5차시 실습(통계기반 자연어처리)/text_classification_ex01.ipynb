{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e356206",
   "metadata": {
    "id": "8e356206"
   },
   "source": [
    "# 텍스트 분류 실습 과제 노트북\n",
    "\n",
    "## 과제 목표\n",
    "\n",
    "하나의 텍스트 데이터셋(예: 리뷰, 댓글, SNS 글 등)에 대해\n",
    "\n",
    "1. 텍스트 데이터를 로드하고 간단한 EDA(탐색적 데이터 분석)를 수행한다.\n",
    "2. TF-IDF 벡터화를 적용하고,\n",
    "3. 세 가지 모델을 학습 및 비교한다.\n",
    "   - 로지스틱 회귀 (`LogisticRegression`)\n",
    "   - 나이브 베이즈 (`MultinomialNB`)\n",
    "   - 선형 SVM (`LinearSVC`)\n",
    "4. 평가지표(특히 macro-F1)를 기준으로 모델 성능을 비교·분석한다.\n",
    "5. 간단한 보고서(요약 문장)를 마크다운으로 정리한다.\n",
    "\n",
    "---\n",
    "\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771810f2",
   "metadata": {
    "id": "771810f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "# TODO: 필요한 라이브러리를 임포트하세요.\n",
    "# 예시:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "print(\"라이브러리 임포트 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b0306",
   "metadata": {
    "id": "e35b0306"
   },
   "source": [
    "## 1. 데이터 불러오기 및 전처리\n",
    "\n",
    "### 1-1. CSV 파일 불러오기\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646b3c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\데이터분석가 부트캠프\\\\실습\\\\DataAnalysis_bootcamp\\\\5차시 실습(통계기반 자연어처리)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dbbe68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie_reviews.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad61be",
   "metadata": {
    "id": "2dad61be"
   },
   "source": [
    "### 1-2. 간단 EDA\n",
    "\n",
    "- 데이터 크기 확인 (`df.shape`)\n",
    "- 레이블 분포 확인 (`value_counts()`)\n",
    "- 결측값 여부 확인 (`isna().sum()`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f680512c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f58fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    8\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "df_na = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6xWJYQ0k-F_l",
   "metadata": {
    "id": "6xWJYQ0k-F_l"
   },
   "source": [
    "1-3. 데이터 전처리(함수로 구현)\n",
    "\n",
    "\n",
    "*   정제 및 정규화(정규식사용), 어간/표제어처리, 불용어 제거\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd13715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어 불러오기\n",
    "with open('stopwords-ko.txt', encoding='utf-8') as f:\n",
    "    stopwords = set(w.strip() for w in f if w.strip())\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76cd24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "okt = Okt()\n",
    "def preprocess_text(text:str):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^0-9a-zA-Z가-힣\\s]',' ', text).strip() # 정규식 사용 및 양끝 공백 처리\n",
    "    text = re.sub(r'\\s+', ' ', text) # 연속되는 공백 처리\n",
    "\n",
    "    morphs = okt.morphs(text, norm=True, stem=True) # 어간,표제어 처리\n",
    "    return [w for w in morphs if w not in stopwords] # 불용어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4TWtAzC795G-",
   "metadata": {
    "id": "4TWtAzC795G-"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ab80e9f",
   "metadata": {
    "id": "3ab80e9f"
   },
   "source": [
    "## 2. 학습/테스트 데이터 분리\n",
    "\n",
    "- `train_test_split`으로 데이터를 분리\n",
    "- 가능하면 `stratify=df[\"label\"]` 옵션을 사용해 **레이블 비율을 유지**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4c29066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 층화 추출\n",
    "df_sample, _ = train_test_split(df_na, train_size=10000, stratify=df_na['label'], random_state=42)\n",
    "\n",
    "# train/test 분할\n",
    "X = df_sample['document']\n",
    "y = df_sample['label']\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "(len(x_tr), len(x_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2278c23",
   "metadata": {
    "id": "f2278c23"
   },
   "source": [
    "## 3. 공통 함수: 모델 학습 & 평가\n",
    "\n",
    "- TF-IDF + 분류기를 하나의 `Pipeline`으로 묶어서 사용\n",
    "- `classification_report`와 `macro-F1` 점수를 함께 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "lr_ct_clf = Pipeline(steps=[\n",
    "    ('vect', CountVectorizer(\n",
    "        tokenizer=preprocess_text,\n",
    "        token_pattern=None,\n",
    "        lowercase=False\n",
    "    )),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "nb_ct_clf = Pipeline(steps=[\n",
    "    ('vect', CountVectorizer(\n",
    "        tokenizer=preprocess_text,\n",
    "        token_pattern=None,\n",
    "        lowercase=False\n",
    "    )),\n",
    "    ('model', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "svm_ct_clf = Pipeline(steps=[\n",
    "    ('vect', CountVectorizer(\n",
    "        tokenizer=preprocess_text,\n",
    "        token_pattern=None,\n",
    "        lowercase=False\n",
    "    )),\n",
    "    ('model', LinearSVC())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ed17b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "lr_tfidf_clf = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(\n",
    "        tokenizer=preprocess_text,\n",
    "        token_pattern=None,\n",
    "        lowercase=False\n",
    "    )),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "nb_tfidf_clf = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(\n",
    "        tokenizer=preprocess_text,\n",
    "        token_pattern=None,\n",
    "        lowercase=False\n",
    "    )),\n",
    "    ('model', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "svm_tfidf_clf = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(\n",
    "        tokenizer=preprocess_text,\n",
    "        token_pattern=None,\n",
    "        lowercase=False\n",
    "    )),\n",
    "    ('model', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b8b4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "lr_param_grid = {\n",
    "    'vect__ngram_range': [(1,1), (1,2)],\n",
    "    'vect__min_df': [1,2,3],\n",
    "    'model__C': [0.1, 0.5, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "nb_param_grid = {\n",
    "    'vect__ngram_range': [(1,1), (1,2)],\n",
    "    'vect__min_df': [1,2,3],\n",
    "    'model__alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "svm_param_grid = {\n",
    "    'vect__ngram_range': [(1,1), (1,2)],\n",
    "    'vect__min_df': [1,2,3],\n",
    "    'model__C': [0.1, 0.5, 1.0, 10.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda17f34",
   "metadata": {
    "id": "eda17f34"
   },
   "source": [
    "## 4. 모델별 학습 & 평가\n",
    "\n",
    "세 가지 모델을 모두 학습해 보고 성능을 비교\n",
    "\n",
    "1. 로지스틱 회귀 (`LogisticRegression`)\n",
    "2. 나이브 베이즈 (`MultinomialNB`)\n",
    "3. LinearSVC (`LinearSVC`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e6704a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== LogisticRegression + TF-IDF ==\n",
      "Best params: {'model__C': 0.5, 'vect__min_df': 1, 'vect__ngram_range': (1, 2)}\n",
      "Best macro-F1 (cv): 0.7972174571236573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.823     0.808     0.815      1000\n",
      "           1      0.811     0.826     0.819      1000\n",
      "\n",
      "    accuracy                          0.817      2000\n",
      "   macro avg      0.817     0.817     0.817      2000\n",
      "weighted avg      0.817     0.817     0.817      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    lr_ct_clf,\n",
    "    param_grid=lr_param_grid,\n",
    "    scoring=\"f1_macro\", # 불균형 데이터 고려하면 macro-F1 추천\n",
    "    cv=3,\n",
    "    n_jobs=1 # okt를 쓰게되면 병렬처리가 불가능, 미리 전처리하고 기본 토크나이저를 쓰면 해결가능\n",
    ")\n",
    "\n",
    "gs_lr.fit(x_tr, y_tr)\n",
    "print(\"== LogisticRegression + CountVectorizer ==\")\n",
    "print(\"Best params:\", gs_lr.best_params_)\n",
    "print(\"Best macro-F1 (cv):\", gs_lr.best_score_)\n",
    "\n",
    "best_lr = gs_lr.best_estimator_\n",
    "y_pred = best_lr.predict(x_te)\n",
    "print(classification_report(y_te, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9ebdf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 전처리 없이\n",
    "lr_ct_clf = Pipeline(steps=[\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2), min_df=1)),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "nb_ct_clf = Pipeline(steps=[\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2), min_df=1)),\n",
    "    ('model', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "svm_ct_clf = Pipeline(steps=[\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2), min_df=1)),\n",
    "    ('model', LinearSVC())\n",
    "])\n",
    "\n",
    "lr_tfidf_clf = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(ngram_range=(1,2), min_df=1)),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "nb_tfidf_clf = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(ngram_range=(1,2), min_df=1)),\n",
    "    ('model', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "svm_tfidf_clf = Pipeline(steps=[\n",
    "    ('vect', TfidfVectorizer(ngram_range=(1,2), min_df=1)),\n",
    "    ('model', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60c8665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== LogisticRegression + CountVectorizer(전처리X) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.742     0.774     0.758      1000\n",
      "           1      0.764     0.731     0.747      1000\n",
      "\n",
      "    accuracy                          0.752      2000\n",
      "   macro avg      0.753     0.752     0.752      2000\n",
      "weighted avg      0.753     0.752     0.752      2000\n",
      "\n",
      "\n",
      "== NaiveBayes + CountVectorizer(전처리X) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.769     0.759     0.764      1000\n",
      "           1      0.762     0.772     0.767      1000\n",
      "\n",
      "    accuracy                          0.765      2000\n",
      "   macro avg      0.766     0.766     0.765      2000\n",
      "weighted avg      0.766     0.765     0.765      2000\n",
      "\n",
      "\n",
      "== LinearSVC + CountVectorizer(전처리X) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.807     0.658     0.725      1000\n",
      "           1      0.711     0.843     0.772      1000\n",
      "\n",
      "    accuracy                          0.750      2000\n",
      "   macro avg      0.759     0.750     0.748      2000\n",
      "weighted avg      0.759     0.750     0.748      2000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_ct_clf.fit(x_tr, y_tr)\n",
    "lr_ct_pred = lr_ct_clf.predict(x_te)\n",
    "print('== LogisticRegression + CountVectorizer(전처리X) ==')\n",
    "print(classification_report(y_te, lr_ct_pred, digits=3))\n",
    "print()\n",
    "nb_ct_clf.fit(x_tr, y_tr)\n",
    "nb_ct_pred = nb_ct_clf.predict(x_te)\n",
    "print('== NaiveBayes + CountVectorizer(전처리X) ==')\n",
    "print(classification_report(y_te, nb_ct_pred, digits=3))\n",
    "print()\n",
    "svm_ct_clf.fit(x_tr, y_tr)\n",
    "svm_ct_pred = svm_ct_clf.predict(x_te)\n",
    "print('== LinearSVC + CountVectorizer(전처리X) ==')\n",
    "print(classification_report(y_te, svm_ct_pred, digits=3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79c3ddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== LogisticRegression + TfidfVectorizer(전처리X) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.742     0.766     0.754      1000\n",
      "           1      0.758     0.734     0.746      1000\n",
      "\n",
      "    accuracy                          0.750      2000\n",
      "   macro avg      0.750     0.750     0.750      2000\n",
      "weighted avg      0.750     0.750     0.750      2000\n",
      "\n",
      "\n",
      "== NaiveBayes + TfidfVectorizer(전처리X) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.766     0.771     0.769      1000\n",
      "           1      0.770     0.765     0.767      1000\n",
      "\n",
      "    accuracy                          0.768      2000\n",
      "   macro avg      0.768     0.768     0.768      2000\n",
      "weighted avg      0.768     0.768     0.768      2000\n",
      "\n",
      "\n",
      "== LinearSVC + TfidfVectorizer(전처리X) ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.753     0.773     0.763      1000\n",
      "           1      0.767     0.746     0.756      1000\n",
      "\n",
      "    accuracy                          0.759      2000\n",
      "   macro avg      0.760     0.760     0.759      2000\n",
      "weighted avg      0.760     0.759     0.759      2000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf_clf.fit(x_tr, y_tr)\n",
    "lr_tfidf_pred = lr_tfidf_clf.predict(x_te)\n",
    "print('== LogisticRegression + TfidfVectorizer(전처리X) ==')\n",
    "print(classification_report(y_te, lr_tfidf_pred, digits=3))\n",
    "print()\n",
    "nb_tfidf_clf.fit(x_tr, y_tr)\n",
    "nb_tfidf_pred = nb_tfidf_clf.predict(x_te)\n",
    "print('== NaiveBayes + TfidfVectorizer(전처리X) ==')\n",
    "print(classification_report(y_te, nb_tfidf_pred, digits=3))\n",
    "print()\n",
    "svm_tfidf_clf.fit(x_tr, y_tr)\n",
    "svm_tfidf_pred = svm_tfidf_clf.predict(x_te)\n",
    "print('== LinearSVC + TfidfVectorizer(전처리X) ==')\n",
    "print(classification_report(y_te, svm_tfidf_pred, digits=3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d539b8d",
   "metadata": {
    "id": "8d539b8d"
   },
   "source": [
    "## 5. 성능 비교 표 만들기\n",
    "\n",
    "세 모델의 macro-F1 점수를 하나의 표로 정리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36da8ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           lr_ct   nb_ct  svm_ct lr_tfidf nb_tfidf svm_tfidf\n",
      "macro_f1  0.7524  0.7655  0.7483   0.7499   0.7680    0.7595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_20076\\617810754.py:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_metrics = df_metrics.applymap(lambda x: f\"{x:.4f}\") # map은 데이터프레임에 못씀.\n"
     ]
    }
   ],
   "source": [
    "lr_ct_f1 = f1_score(y_te, lr_ct_pred, average='macro')\n",
    "nb_ct_f1 = f1_score(y_te, nb_ct_pred, average='macro')\n",
    "svm_ct_f1 = f1_score(y_te, svm_ct_pred, average='macro')\n",
    "lr_tfidf_f1 = f1_score(y_te, lr_tfidf_pred, average='macro')\n",
    "nb_tfidf_f1 = f1_score(y_te, nb_tfidf_pred, average='macro')\n",
    "svm_tfidf_f1 = f1_score(y_te, svm_tfidf_pred, average='macro')\n",
    "\n",
    "model_names = ['lr_ct', 'nb_ct', 'svm_ct', 'lr_tfidf', 'nb_tfidf', 'svm_tfidf']\n",
    "f1_scores = [lr_ct_f1, nb_ct_f1, svm_ct_f1, lr_tfidf_f1, nb_tfidf_f1, svm_tfidf_f1]\n",
    "\n",
    "df_metrics = pd.DataFrame([f1_scores], index=['macro_f1'], columns=model_names)\n",
    "df_metrics = df_metrics.applymap(lambda x: f\"{x:.4f}\") # map은 데이터프레임에 못씀.\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1070ea0",
   "metadata": {
    "id": "e1070ea0"
   },
   "source": [
    "\n",
    "\n",
    "### 6. 나이브 베이즈: 클래스별 대표 단어\n",
    "\n",
    "- `MultinomialNB`의 `feature_log_prob_`를 이용해\n",
    "- 각 클래스에서 중요한 단어 TOP-N을 뽑기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d807415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '000 000' '000 000점' ... '힙합을' '힙합을 능욕하는' '힛힛']\n",
      "===클래스 0 대표 단어===\n",
      "['없고' '이게' '이건' '영화는' '이런' '정말' '그냥' '진짜' '너무' '영화']\n",
      "===클래스 1 대표 단어===\n",
      "['드라마' '영화를' '보고' 'ㅋㅋ' '이런' '최고의' '진짜' '너무' '정말' '영화']\n"
     ]
    }
   ],
   "source": [
    "vect = nb_ct_clf.named_steps['vect']\n",
    "nb = nb_ct_clf.named_steps['model']\n",
    "\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "print(feature_names)\n",
    "\n",
    "for i, c in enumerate(nb.classes_):\n",
    "    print(f'===클래스 {c} 대표 단어===')\n",
    "    log_prob = nb.feature_log_prob_[i]\n",
    "    top10_idx = log_prob.argsort()[-10:] # 상위 10등\n",
    "    print(feature_names[top10_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aad3b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '000 000' '000 000점' ... '힙합을' '힙합을 능욕하는' '힛힛']\n",
      "===클래스 0 대표 단어===\n",
      "['이건' '이런' '아깝다' '이게' '정말' '쓰레기' '그냥' '진짜' '너무' '영화']\n",
      "===클래스 1 대표 단어===\n",
      "['재밌게' '드라마' '재밌어요' 'ㅋㅋ' '최고의' '최고' '진짜' '너무' '정말' '영화']\n"
     ]
    }
   ],
   "source": [
    "vect = nb_tfidf_clf.named_steps['vect']\n",
    "nb = nb_tfidf_clf.named_steps['model']\n",
    "\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "print(feature_names)\n",
    "\n",
    "for i, c in enumerate(nb.classes_):\n",
    "    print(f'===클래스 {c} 대표 단어===')\n",
    "    log_prob = nb.feature_log_prob_[i]\n",
    "    top10_idx = log_prob.argsort()[-10:] # 상위 10등\n",
    "    print(feature_names[top10_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b2ba6",
   "metadata": {
    "id": "ce6b2ba6"
   },
   "source": [
    "### 7. LinearSVC: 단어 가중치 분석\n",
    "\n",
    "- `coef_`를 이용해 각 단어가 어떤 클래스로 기울게 만드는지 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92b11623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ... -0.06051    -0.06051\n",
      "  -0.29379038]]\n",
      "== 긍정에 강하게 기여하는 단어 ==\n",
      "['좋다' '재밌음' '재밌네' '최고다' '좋아요' '재밌습니다' '재밋다' '재미있어요' '재밌어요' '최고']\n",
      "== 부정에 강하게 기여하는 단어 ==\n",
      "['재미없음' '최악' '재미없다' '쓰레기' '재미없어' '별루' '지루하다' '별로' '쓰레기영화' '너무 재미있다']\n"
     ]
    }
   ],
   "source": [
    "vect = svm_ct_clf.named_steps['vect']\n",
    "clf = svm_ct_clf.named_steps['model']\n",
    "\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "coef = clf.coef_ # 값이크면:긍정, 값이작으면:부정, 절댓값이크면:영향력큼\n",
    "print(coef)\n",
    "top10_pos = coef[0].argsort()[-10:]\n",
    "print(\"== 긍정에 강하게 기여하는 단어 ==\")\n",
    "print(feature_names[top10_pos])\n",
    "\n",
    "top10_neg = coef[0].argsort()[:10]\n",
    "print(\"== 부정에 강하게 기여하는 단어 ==\")\n",
    "print(feature_names[top10_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab8d0503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25178405  0.16785603  0.08392802 ... -0.16223922 -0.16223922\n",
      "  -0.37359538]]\n",
      "== 긍정에 강하게 기여하는 단어 ==\n",
      "['재밌게' '그리고' '다시' '눈물이' '명작' '좋다' '최고다' '10점' '최고' '최고의']\n",
      "== 부정에 강하게 기여하는 단어 ==\n",
      "['아깝다' '쓰레기' '최악의' 'ㅡㅡ' '없고' '지루하다' '최악' '스토리' '없는' '뭐야']\n"
     ]
    }
   ],
   "source": [
    "vect = svm_tfidf_clf.named_steps['vect']\n",
    "clf = svm_tfidf_clf.named_steps['model']\n",
    "\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "coef = clf.coef_ # 값이크면:긍정, 값이작으면:부정, 절댓값이크면:영향력큼\n",
    "print(coef)\n",
    "top10_pos = coef[0].argsort()[-10:]\n",
    "print(\"== 긍정에 강하게 기여하는 단어 ==\")\n",
    "print(feature_names[top10_pos])\n",
    "\n",
    "top10_neg = coef[0].argsort()[:10]\n",
    "print(\"== 부정에 강하게 기여하는 단어 ==\")\n",
    "print(feature_names[top10_neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057f083",
   "metadata": {},
   "source": [
    "# 결과 분석\n",
    "\n",
    "macro_f1 기준 nNaive Bayes와 TfidfVectorizer 조합이 0.7680으로 좋은 성능을 보였고 그 다음으로 Naive Bayes와 CountVectorizer가 좋은 성능을 보였다.\n",
    "따라서 Naive Bayes가 이 데이테에 대해서 가장 좋은 성능을 가지는 모델이라고 볼 수 있다.\n",
    "\n",
    "시간이 부족하여 전처리를 하지 못했는데, 때문에 '--', 'ㅋㅋ' 이런 정제되지 않은 단어들이 포함된 것을 확인할 수 있었다.\n",
    "전처리를 했으면 또 다른 결과가 나왔을 수도 있고 gridsearch를 통해 파라미터 튜닝을 한다면 더 좋은 성능이 나올 것으로 기대한다.\n",
    "\n",
    "          lr_ct   nb_ct   svm_ct  lr_tfidf nb_tfidf svm_tfidf\n",
    "macro_f1  0.7524  0.7655  0.7483   0.7499   0.7680    0.7595"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1dPo38_lRU067s7n4srXBSQ4NAOXALiZp",
     "timestamp": 1763620017300
    }
   ]
  },
  "kernelspec": {
   "display_name": "stnlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
